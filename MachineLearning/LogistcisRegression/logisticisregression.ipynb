{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caa1fd4",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "- Despite its name, it's a CLASSIFICATION algorithm, not regression\n",
    "- Used for binary classification (Yes/No, 0/1, True/False)\n",
    "- Predicts the PROBABILITY of an instance belonging to a class\n",
    "- Uses the sigmoid (logistic) function to map predictions to [0, 1]\n",
    "\n",
    "**REAL-WORLD APPLICATIONS:**\n",
    "- Email: Spam or Not Spam?\n",
    "- Medicine: Disease or Healthy?\n",
    "- Finance: Fraud or Legitimate?\n",
    "- Marketing: Click or No Click?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117479a5",
   "metadata": {},
   "source": [
    "\n",
    "KEY CONCEPTS:\n",
    "\n",
    "1. SIGMOID FUNCTION:\n",
    "   σ(z) = 1 / (1 + e^(-z))\n",
    "   - Maps any real number to (0, 1)\n",
    "   - Creates S-shaped curve\n",
    "\n",
    "2. LINEAR COMBINATION:\n",
    "   z = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ\n",
    "   z = β₀ + Σ(βᵢ * xᵢ)\n",
    "\n",
    "3. PREDICTION:\n",
    "   P(y=1|x) = σ(z) = 1 / (1 + e^(-z))\n",
    "\n",
    "4. DECISION BOUNDARY:\n",
    "   If P(y=1|x) >= 0.5 → Predict class 1\n",
    "   If P(y=1|x) < 0.5  → Predict class 0\n",
    "\n",
    "5. COST FUNCTION (Log Loss):\n",
    "   J(β) = -1/m * Σ[y*log(h(x)) + (1-y)*log(1-h(x))]\n",
    "   \n",
    "6. OPTIMIZATION:\n",
    "   Use Gradient Descent to minimize cost function\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
